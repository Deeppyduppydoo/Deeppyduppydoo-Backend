{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Mount drive"
      ],
      "metadata": {
        "id": "NLsamjOoa-mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBW1JwXmPlv2",
        "outputId": "490b4074-ba64-4fd2-8736-41ee7a7f9b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import"
      ],
      "metadata": {
        "id": "ckmITgUoa8WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "qGsGSspKam6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual and Augment"
      ],
      "metadata": {
        "id": "MXXILs0Eax1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define members (subdirectories)\n",
        "members = [\"Oak\", \"Pat\", \"Pookkie\", \"Praewa\", \"Tup\"]\n",
        "image_dir = \"/content/drive/MyDrive/DP/Train_Splitted/train\"\n",
        "augmented_dir = \"/content/drive/MyDrive/DP/Augmented_Train\"  # Save augmented images\n",
        "\n",
        "def augment_pipeline(image_dir, augmented_dir, members, augmentation_factor=3, img_size=(256, 256)):\n",
        "    \"\"\"Loads images, applies augmentation, and saves them in `augmented_dir`.\"\"\"\n",
        "\n",
        "    os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    for member in members:\n",
        "        input_folder = os.path.join(image_dir, member)\n",
        "        output_folder = os.path.join(augmented_dir, member)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        print(f\"Processing {member}: Found {len(image_files)} images\")\n",
        "\n",
        "        for filename in image_files:\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "            img = cv2.resize(img, img_size)\n",
        "            img = np.expand_dims(img, axis=0)\n",
        "\n",
        "            i = 0\n",
        "            for batch in datagen.flow(img, batch_size=1):\n",
        "                save_path = os.path.join(output_folder, f\"aug_{i}_{filename}\")\n",
        "                cv2.imwrite(save_path, batch[0].astype(np.uint8))\n",
        "                i += 1\n",
        "                if i >= augmentation_factor:\n",
        "                    break\n",
        "\n",
        "        print(f\"{member}: {len(os.listdir(output_folder))} images after augmentation\")\n",
        "\n",
        "# Apply augmentation and save images\n",
        "augment_pipeline(image_dir, augmented_dir, members, augmentation_factor=3, img_size=(256, 256))"
      ],
      "metadata": {
        "id": "DduWKVBlarrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Traning"
      ],
      "metadata": {
        "id": "VmzWCcuEb3uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_classes = 5  # Number of classes\n",
        "batch_size = 32\n",
        "epochs = 4\n",
        "learning_rate = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Ensure 3 channels\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load Dataset (Fix: Use correct directory path)\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/DP/Augmented_Train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/DP/Train_Splitted/test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Load Pretrained ResNet Model\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)  # Modify the fully connected layer\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Training Accuracy: {train_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "0lxSqRntb1DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test accuracy"
      ],
      "metadata": {
        "id": "eYTNn_upcAdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Loop (Test Accuracy)\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = 100 * correct / total"
      ],
      "metadata": {
        "id": "S1656drib-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save Model"
      ],
      "metadata": {
        "id": "3sff_5HNcHR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "torch.save(model.state_dict(), \"handwriting_resnet.pth\")\n",
        "print(\"Model saved!\")"
      ],
      "metadata": {
        "id": "Wqvw65YEcGWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test prediction"
      ],
      "metadata": {
        "id": "DK5e7hs4fV-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "\n",
        "# Load the saved model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(pretrained=False)  # Don't load pretrained weights\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 5)  # Match the number of classes\n",
        "model.load_state_dict(torch.load(\"handwriting_resnet.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),  # Ensure 3 channels\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = \"path/to/your/image.jpg\"  # Replace with the actual path to your image\n",
        "image = Image.open(image_path)\n",
        "image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# Make the prediction\n",
        "with torch.no_grad():\n",
        "  output = model(image)\n",
        "  _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"Predicted class: {predicted_class.item()}\")\n",
        "\n",
        "# Define class names (adjust to your actual classes)\n",
        "class_names = [\"Oak\", \"Pat\", \"Pookkie\", \"Praewa\", \"Tup\"]\n",
        "\n",
        "# Print the predicted class name\n",
        "predicted_class_name = class_names[predicted_class.item()]\n",
        "print(f\"Predicted class name: {predicted_class_name}\")\n"
      ],
      "metadata": {
        "id": "Z4T6-ERlcpkA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}